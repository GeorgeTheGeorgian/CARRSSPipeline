{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5efc7a-d719-4df3-b7c3-3d624ed25145",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b568e2-a186-42d5-8e17-0d542163ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "import glob\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "from astroML.linear_model import LinearRegression, PolynomialRegression\n",
    "import specutils\n",
    "from specutils.fitting import fit_lines\n",
    "from specutils import SpectralRegion\n",
    "from specutils.analysis import line_flux\n",
    "from specutils import Spectrum1D\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "from astropy.modeling.polynomial import Polynomial1D\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "from astropy.modeling.fitting import LevMarLSQFitter, LinearLSQFitter\n",
    "from astropy.modeling.models import Gaussian1D\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.fitting import fit_continuum\n",
    "from astropy.convolution import convolve, Gaussian1DKernel\n",
    "from scipy.ndimage import convolve as sci_convolve\n",
    "from scipy.ndimage import convolve1d\n",
    "from matplotlib.lines import Line2D\n",
    "from astropy.nddata import NDData\n",
    "import time\n",
    "import logging as logger\n",
    "from scipy import ndimage\n",
    "from scipy import optimize\n",
    "from scipy.linalg import lstsq\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from specutils.analysis import centroid\n",
    "from astropy.modeling import models\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "from scipy.ndimage import median_filter\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table, hstack\n",
    "import RSSMOSPipeline\n",
    "from RSSMOSPipeline import RSSMOSTools as rss\n",
    "import importlib\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688e09b-0b01-4c16-abab-96dc19b00f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes plots larger/easier to read\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a54eb-ff02-4cc2-ae19-5a4aafdb02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units for flux and wavelength values, respectively.\n",
    "flux_units = u.erg*(u.cm)**-2*(u.s)**-1*(u.AA)**-1\n",
    "wave_units = u.AA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f397b9dd-ab60-429f-b1df-f2c08787b7e5",
   "metadata": {},
   "source": [
    "# SALTRSSCalPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15e9c8-0d5c-4dd1-a50f-263c1aa4cf5c",
   "metadata": {},
   "source": [
    "## - File Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9dd61e-ee54-4940-a15a-39d8fe2b5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where all masks are contained\n",
    "data_dir = '/home/george/Downloads/DATASETS/'\n",
    "config_name = 'path_file_COSMOS-mask-B.config'\n",
    "# spectroscopic data should be in  ../<mask>/<grating>/<dither>/reduced\n",
    "# where reduced is the name of the folder that RSSMOSPipeline outputs into\n",
    "def get_paths(data_dir, config_name):\n",
    "    # open configuration file where mask name and ID are declared\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(data_dir+config_name)\n",
    "    mask_name = config['Mask Info']['mask_name']\n",
    "    mask_id = config['Mask Info']['mask_id']\n",
    "\n",
    "    # declare paths to HETDEX catalogue (can be any catalgue you're comparing results to)\n",
    "    HETDEX_path = data_dir+'HETDEX_catalogues'\n",
    "    dir_mask = data_dir + mask_name\n",
    "\n",
    "    # declare directories for each grating\n",
    "    dir_red = dir_mask+'/PG0900'\n",
    "    dir_green = dir_mask + '/PG2300'\n",
    "    dir_blue = dir_mask + '/PG3000'\n",
    "    # and each reduce folder in each dither\n",
    "    l_path = f'/Dither-/reduce/{mask_name}_{mask_id}/1DSpec_2DSpec_stackAndExtract_iterative/'\n",
    "    u_path = f'/Dither+/reduce/{mask_name}_{mask_id}/1DSpec_2DSpec_stackAndExtract_iterative/'\n",
    "\n",
    "    # make dictionary of paths\n",
    "    paths_dict = {'mask_name' :mask_name,\n",
    "            'mask_id' :mask_id, \n",
    "            'HETDEX_path' :HETDEX_path,\n",
    "            \"dir_mask\" :dir_mask,\n",
    "            \"dir_red\" :dir_red,\n",
    "            \"dir_green\" :dir_green,\n",
    "            \"dir_blue\" :dir_blue,\n",
    "            'l_path' :l_path,\n",
    "            'u_path' :u_path}\n",
    "    \n",
    "    return paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be733213-3262-448e-a51a-62a7a399b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_calibrated_specs(SLIT):\n",
    "    \n",
    "    '''\n",
    "    Finds flux calibrated spectra to be used for reprojection and continuum comparison.\n",
    "    dir_red, dir_green, dir_blue must be strings containing the respective directories to each grating\n",
    "    Declare data from all gratings and dithers\n",
    "    Works if data is missing for a single dither\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    # get files \n",
    "    paths = get_paths(data_dir,config_name)\n",
    "    color = []\n",
    "    #red\n",
    "    if os.path.exists(paths[\"dir_red\"]+'/Dither-/') and os.path.exists(paths[\"dir_red\"]+'/Dither+/'):\n",
    "        red_setting_l = fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        red_setting_u = fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        if glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_1D*{SLIT}.fits') and glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "            red_setting1D_l = fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            red_setting1D_u = fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            red_setting1D = [red_setting1D_l,red_setting1D_u]\n",
    "        red_setting = [red_setting_l,red_setting_u]\n",
    "        color.append('red')\n",
    "        color.append('red')\n",
    "    else:\n",
    "        \n",
    "        if os.path.exists(paths[\"dir_red\"]+'/Dither-/'):\n",
    "            red_setting = [fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_1D*{SLIT}.fits'):\n",
    "                red_setting1D = [fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('red')\n",
    "        elif os.path.exists(paths[\"dir_red\"]+'/Dither+/'):\n",
    "            red_setting = [fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "                red_setting1D = [fits.open(glob.glob(f'{paths[\"dir_red\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('red')\n",
    "    \n",
    "    #green\n",
    "    if os.path.exists(paths[\"dir_green\"]+'/Dither-/') and os.path.exists(paths[\"dir_green\"]+'/Dither+/'):\n",
    "        green_setting_l = fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        green_setting_u = fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        if glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_1D*{SLIT}.fits') and glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "            green_setting1D_l = fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            green_setting1D_u = fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            green_setting1D = [green_setting1D_l,green_setting1D_u]\n",
    "        green_setting = [green_setting_l,green_setting_u]\n",
    "        color.append('green')\n",
    "        color.append('green')\n",
    "    else:\n",
    "        if os.path.exists(paths[\"dir_green\"]+'/Dither-/'):\n",
    "            green_setting = [fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_1D*{SLIT}.fits'):\n",
    "                green_setting1D = [fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('green')\n",
    "        elif os.path.exists(paths[\"dir_green\"]+'/Dither+/'):\n",
    "            green_setting = [fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "                green_setting1D = [fits.open(glob.glob(f'{paths[\"dir_green\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('green')\n",
    "    #blue\n",
    "    if os.path.exists(paths[\"dir_blue\"]+'/Dither-/') and os.path.exists(paths[\"dir_blue\"]+'/Dither+/'):\n",
    "        blue_setting_l = fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        blue_setting_u = fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])\n",
    "        if glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_1D*{SLIT}.fits') and glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "            blue_setting1D_l = fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            blue_setting1D_u = fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])\n",
    "            blue_setting1D = [blue_setting1D_l,blue_setting1D_u]\n",
    "        blue_setting = [blue_setting_l,blue_setting_u]\n",
    "        color.append('blue')\n",
    "        color.append('blue')\n",
    "    else:\n",
    "        if os.path.exists(paths[\"dir_blue\"]+'/Dither-/'):\n",
    "            blue_setting = [fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_1D*{SLIT}.fits'):\n",
    "                blue_setting1D = [fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither-/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('blue')\n",
    "        elif os.path.exists(paths[\"dir_blue\"]+'/Dither+/'):\n",
    "            blue_setting = [fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_2D*{SLIT}.fits')[0])]\n",
    "            if glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_1D*{SLIT}.fits'):\n",
    "                blue_setting1D = [fits.open(glob.glob(f'{paths[\"dir_blue\"]}/Dither+/FLUXcal_1D*{SLIT}.fits')[0])]\n",
    "            color.append('blue')\n",
    "    \n",
    "    full_settings = np.concatenate([red_setting,green_setting, blue_setting])\n",
    "    try :\n",
    "        if red_setting1D and green_setting1D and blue_setting1D:\n",
    "            full_settings1D = np.concatenate([red_setting1D,green_setting1D, blue_setting1D])\n",
    "            HETDEX_range_settings = np.concatenate([green_setting1D, blue_setting1D])\n",
    "    except NameError:\n",
    "            full_settings1D = []\n",
    "            HETDEX_range_settings = []\n",
    "    path_list_1D = glob.glob(f'{paths[\"dir_mask\"]}/FLUXcal_1D*{SLIT}_comb.fits')\n",
    "    if len(path_list_1D) >0 :\n",
    "        combined_spec = fits.open(path_list_1D[0])\n",
    "    else:\n",
    "        combined_spec = None\n",
    "        \n",
    "    #returns from red --> blue order\n",
    "    return full_settings,full_settings1D,HETDEX_range_settings, combined_spec, color, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b4dc5-f1d9-4b74-9a57-7ae4b7bb629d",
   "metadata": {},
   "source": [
    "## - Declare WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd15018-5a0b-4e95-8b40-afae792822f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Used to convert WCS to world coordinates (Angstrom in our case)\n",
    "This only returns wavelengths for non reprojected data\n",
    "For reprojected data, it returns a linear array called 'L' that needs to be put into an exponential function as described in the HDU header\n",
    "'''\n",
    "def WCS2World(hdu):\n",
    "    wcs = WCS(hdu[0].header)\n",
    "    if hdu[0].data.ndim == 2:\n",
    "        pixel_coords = np.arange(hdu[0].data.shape[1])\n",
    "        pixel_array = np.column_stack((pixel_coords, np.zeros_like(pixel_coords)))\n",
    "        world_coords = wcs.pixel_to_world_values(pixel_array[:, 0], pixel_array[:, 1])\n",
    "        L = world_coords[0]  \n",
    "        return L\n",
    "    elif hdu[0].data.ndim == 1:\n",
    "        pixel_coords = np.arange(hdu[0].data.shape[0])\n",
    "        world_coords = wcs.pixel_to_world_values(pixel_coords)\n",
    "        wavelength_array = world_coords \n",
    "        return wavelength_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d693f6c-4124-4948-aff1-e2baa9ae312f",
   "metadata": {},
   "source": [
    "## - Sensitivity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc5437-f55b-4b71-ab71-bdd88db768e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sens_func(SDSS_star_folder,sci_spec, starSLITS):   \n",
    "\n",
    "    '''\n",
    "    Using the observed and known star spectra, a sensitivity function is made by dividing the observed spectra (counts) by the known\n",
    "    spectra (flux units). First the 2D star spectra are summed after masking out chip gaps, and are interpolated on a wavelength range. \n",
    "    Then we take the corresponding flux calibrated spectra from SDSS and divide. Returns the sensitivity function to be used in \n",
    "    flux_calibration, as well as other parameters. \n",
    "    '''\n",
    "    # pull data and file names from FITS files\n",
    "    SDSS_star_path = str(SDSS_star_folder)\n",
    "    star_diagnostics = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(SDSS_star_path))), 'star_diagnostics')\n",
    "    os.makedirs(star_diagnostics, exist_ok=True)\n",
    "    sci_spec_path = str(sci_spec)\n",
    "    sci_spec = fits.open(sci_spec_path)\n",
    "\n",
    "    # make a list of SDSS stars and corresponding observed stars\n",
    "    paths=get_paths(data_dir,config_name)\n",
    "\n",
    "\n",
    "    \n",
    "    SDSS_star_specs = [fits.open(glob.glob(f'{SDSS_star_path}*SLIT{num}.fits')[0]) for num in starSLITS]\n",
    "    observed_star_specs = [fits.open(glob.glob(f'{color}{path}2D_noSky_{paths[\"mask_name\"]}_{paths[\"mask_id\"]}_SLIT{num}.fits')[0]) for num in starSLITS]\n",
    "    print(starSLITS)\n",
    "    sci_data = sci_spec[0].data\n",
    "    nmad = 1.4826 * np.median(np.abs(sci_data - np.median(sci_data)))\n",
    "    atol = .00001 * nmad\n",
    "    zero_mask_sci = np.isclose(sci_data, 0, atol=atol)\n",
    "\n",
    "\n",
    "\n",
    "    # very simple chip gap zapper, as RSSMOS ouputs chipgaps = 0, and we cant average zeros\n",
    "    # chip gaps will have values at zero and very close to zero, so we mask out those values and neighboring 8 pixels which might pop through\n",
    "    zero_mask_sci_ext = np.zeros_like(zero_mask_sci, dtype=bool)\n",
    "    for i in range(sci_data.shape[0]):\n",
    "        for j in range(sci_data.shape[1]):\n",
    "            if zero_mask_sci[i,j]:\n",
    "              zero_mask_sci_ext[i,max(j-8,0):min(j+9, sci_data.shape[1])] = True  \n",
    "    sci_data[zero_mask_sci_ext]=np.nan\n",
    "\n",
    "\n",
    "    \n",
    "    # initialize lists to store sens functions, tuple ranges etc\n",
    "    sens_funcs = []\n",
    "    sens_funcs_inverse = []\n",
    "    observed_wavs = []\n",
    "    ranges = []\n",
    "    interp_stars = []\n",
    "\n",
    "    # loop over all pairs of specs to generate sens functions for each star, as well as interpolation functions for each star.\n",
    "    for star_spec_cal, star_spec_obs, slit in zip(SDSS_star_specs,observed_star_specs, starSLITS):\n",
    "        print(slit)\n",
    "        star_data_cal = star_spec_cal[1].data\n",
    "        star_data_obs = star_spec_obs[0].data\n",
    "        print(star_data_obs.shape)\n",
    "        star_data_obs = star_data_obs.astype(float)\n",
    "\n",
    "        # fix poor star spec sky subtraction\n",
    "        star_data_obs=check_skysub(cont=5,sky=1, data = star_data_obs)\n",
    "        check_skysub(cont=5,sky=1, data = star_data_obs)\n",
    "        \n",
    "\n",
    "        # mask out values very close to zero to zap chip gaps and prevent infinities  \n",
    "        star_data_obs= np.nansum(star_data_obs, axis = 0)\n",
    "        nmad = 1.4826 * np.median(np.abs(star_data_obs - np.median(star_data_obs)))\n",
    "        atol = .02 * nmad\n",
    "        zero_mask_obs = np.isclose(star_data_obs, 0, atol=atol)\n",
    "        star_data_obs[zero_mask_obs]=np.nan\n",
    "        # get the wavelength arrays for all stars\n",
    "        obs_wavs = WCS2World(star_spec_obs)\n",
    "\n",
    "        # get the min and max values for each stars wavelength array, then append as tuples    \n",
    "        min_val = obs_wavs[0]\n",
    "        max_val = obs_wavs[-1]\n",
    "        ranges.append((min_val, max_val))\n",
    "\n",
    "        file_name = os.path.basename(sci_spec_path).split('/')[-1]\n",
    "        if sci_data.ndim == 1:\n",
    "            sci_data = sci_spec[1].data\n",
    "        elif sci_data.ndim ==2:\n",
    "            sci_data = sci_spec[0].data\n",
    "            SLIT = sci_spec[0].header['EXTNAME']\n",
    "\n",
    "        #interpolate over the wavelength values from dataset to generate a model.\n",
    "        calibrated_wavs = 10**star_spec_cal[1].data['loglam']\n",
    "        calibrated_flux = star_spec_cal[1].data['flux']*10**-17\n",
    "        for i in range(1, len(calibrated_flux)):\n",
    "            #include fix to avoid infinities\n",
    "            if np.isclose(calibrated_flux[i], 0, atol=10e-17):\n",
    "                calibrated_flux[i] = calibrated_flux[i-1] \n",
    "        print(obs_wavs.shape)\n",
    "        print(calibrated_wavs.shape)\n",
    "        print(calibrated_flux.shape)\n",
    "        calibrated_flux_interp_func = interp1d(calibrated_wavs,calibrated_flux, bounds_error =False, fill_value = np.nan)\n",
    "        calibrated_flux_interp = calibrated_flux_interp_func(obs_wavs)\n",
    "        calibrated_wavs = calibrated_wavs*wave_units\n",
    "        calibrated_flux = calibrated_flux*flux_units\n",
    "\n",
    "        #defines the sensitivity and inverse sensitivity functions\n",
    "        obs_flux = (star_data_obs)*u.ph\n",
    "        sensitivity_function = obs_flux/calibrated_flux_interp\n",
    "        \n",
    "        #append everything\n",
    "        sens_funcs.append(sensitivity_function)\n",
    "        observed_wavs.append(obs_wavs)\n",
    "        interp_star = interp1d(obs_wavs, sensitivity_function, bounds_error =False, fill_value = np.nan)\n",
    "        interp_stars.append(interp_star)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        #plots the calibrated and uncalibrated star spectrum from SALT.\n",
    "        fig_star, (ax1_star, ax2_star) = plt.subplots(2, 1, sharex=True,figsize=(20,20))\n",
    "        ax1_star.set_title(f'Slit {slit} Star Spectrum from SDSS')\n",
    "\n",
    "        ax1_star.plot(10**star_spec_cal[1].data['loglam'], star_spec_cal[1].data['flux']*10**-17)   \n",
    "        ax1_star.set_ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "        ax2_star.set_title(f'Observed Slit {slit} Star Spectrum in PG2300')\n",
    "        ax2_star.plot(obs_wavs, star_data_obs, 'darkorange') \n",
    "        ax2_star.set_xlabel('Wavelength (Å)') \n",
    "        ax2_star.set_ylabel('Counts')  \n",
    "        file_info = star_spec_cal.fileinfo(0) \n",
    "        fits_file_name = os.path.basename(file_info['file'].name)\n",
    "        plot_filename_base = os.path.splitext(fits_file_name)[0]\n",
    "        plot_cal_filename = f'{plot_filename_base}_calibration.png'\n",
    "        plot_cal_full_path = os.path.join(star_diagnostics, plot_cal_filename)\n",
    "\n",
    "      \n",
    "        plt.savefig(plot_cal_full_path, facecolor='w', transparent=False, overwrite=True)\n",
    "         \n",
    "\n",
    "        # plot the interpolated star spectrum and sensitivity function\n",
    "        fig_interp, (ax1_interp, ax3_interp) = plt.subplots(2, 1, sharex=True,figsize=(20,20))\n",
    "        ax1_interp.plot(calibrated_wavs, calibrated_flux, 'o', label = 'Calibrated Star Spectrum')\n",
    "        ax1_interp.set_title('Star Spectrum Interpolation')\n",
    "        ax1_interp.set_ylabel('Counts')  \n",
    "        # create a secondary axis sharing the same x-axis\n",
    "        ax2_interp = ax1_interp\n",
    "        ax2_interp.plot(obs_wavs, calibrated_flux_interp, 'o', mfc='none', label = 'Interpolated Star Spectrum', color = 'darkorange')\n",
    "        ax2_interp.set_ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "        ax3_interp.set_title('Single Sensitivity Function')\n",
    "        ax3_interp.set_xlabel('Wavelength (Å)')\n",
    "        ax3_interp.plot(obs_wavs, sensitivity_function, color = 'blue')\n",
    "        ax3_interp.set_ylabel('Counts/Flux (#/erg/cm$^2$/s/Å)')\n",
    "\n",
    "        lines, labels = ax1_interp.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2_interp.get_legend_handles_labels()\n",
    "        lines3, labels3 = ax3_interp.get_legend_handles_labels()\n",
    "        ax1_interp.legend(lines + lines3, labels + labels3, loc='upper right') \n",
    "\n",
    "\n",
    "    all_observed_wavs = [wave for array in observed_wavs for wave in array]\n",
    "    min_wav = min(all_observed_wavs)\n",
    "    max_wav = max(all_observed_wavs)\n",
    "\n",
    "\n",
    "    final_sens=[]\n",
    "    for wav in all_observed_wavs:\n",
    "        sens_values = np.array([interp_star(wav) for interp_star in interp_stars])\n",
    "        valid_sens_count = np.count_nonzero(~np.isnan(sens_values))\n",
    "        if valid_sens_count == 0:\n",
    "            final_sens.append(0)\n",
    "        elif valid_sens_count == 1:\n",
    "            final_sens.append(sens_values[~np.isnan(sens_values)][0])\n",
    "\n",
    "        else:\n",
    "            average_sensitivity = np.nansum(sens_values) / valid_sens_count\n",
    "            final_sens.append(average_sensitivity)\n",
    "\n",
    "    all_observed_wavs=np.asarray(all_observed_wavs)\n",
    "    final_sens = np.asarray(final_sens)\n",
    "    sorted_indices = np.argsort(all_observed_wavs)\n",
    "    sorted_wavelengths = all_observed_wavs[sorted_indices]\n",
    "    sorted_combined_sensitivity = final_sens[sorted_indices]\n",
    "    labels_set = {}\n",
    "\n",
    "\n",
    "    # plots the calibrated and uncalibrated star spectrum from SALT.\n",
    "    fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "    ax1.set_title('Individual Sensitivity Functions')\n",
    "    for i in range(len(observed_wavs)):\n",
    "            named_colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "            named_colors = [color for color in named_colors if \"blue\" not in color]\n",
    "            random_color = random.choice(named_colors)\n",
    "            label = \"Constituents\" if labels_set.get(\"Constituents\") is None else \" \"\n",
    "            ax1.plot(observed_wavs[i], sens_funcs[i], alpha=0.5, color=random_color, label=label)\n",
    "            labels_set[\"Constituents\"] = True\n",
    "   \n",
    "    \n",
    "    ax2 = ax1\n",
    "    ax2.set_title('Combined Sensitivity Function')\n",
    "    ax2.plot(sorted_wavelengths, sorted_combined_sensitivity, label = 'Full Sensitivity Function', color = 'blue')\n",
    "    ax2.set_xlabel('Wavelength (Å)') \n",
    "    ax2.set_ylabel('Count/Flux (#/erg/cm$^2$/s/Å)')  \n",
    "   \n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    ax1.legend(lines, labels, loc='upper right') \n",
    "    plot_sens_filename = f'combined_sens_function.png'\n",
    "    plot_sens_full_path = os.path.join(star_diagnostics, plot_sens_filename)\n",
    "    plt.savefig(plot_sens_full_path, facecolor='w', transparent=False, overwrite=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return sorted_combined_sensitivity, sci_spec,sorted_wavelengths, sci_data, file_name, star_spec_cal, star_diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673ab98-71f2-4ffd-9994-9122495c0210",
   "metadata": {},
   "source": [
    "## - Flux Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d1b09-e976-4622-9724-7211fb99cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_poly(x,coeffs):\n",
    "    a,b,c = coeffs\n",
    "    return a * x**2 + b * x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d74eb-a8f0-4522-aff2-fc391e0ede9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(coeffs, x, y):\n",
    "    return np.sum((y - custom_poly(x, coeffs))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcc808-5e9e-42d8-acc6-66efc5e9a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to constrain max throughput\n",
    "def derivative_constraint(coeffs, x_c):\n",
    "    a, b, _ = coeffs\n",
    "    return 2 * a * x_c + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e19edf-f299-4962-9a44-c6f5291230aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_calibration(sci_spec_path, SDSS_star_path,Order, starSLITS, max_throughput_wav):\n",
    "\n",
    "\n",
    "    '''\n",
    "    Uses the sensititvty function to flux calibrate science data. It is first subject to polynomial regression by first using AstroML to find an intial guess, then \n",
    "    running a scipy routine starting from the intial guess, but with the added benefit of being able to constrain the max throughput of \n",
    "    each setting. Then we calibrate the 2D science spectra column by column, as we dont expect flux to vary noticably in the spatial dimension.\n",
    "    '''\n",
    "    # create the sensitivity function using the 1D spectra\n",
    "    sensitivity_function, sci_spec,all_observed_wavs, sci_data, file_name, star_spec_cal, star_diagnostics= find_sens_func(SDSS_star_path,sci_spec_path, starSLITS)\n",
    "\n",
    " \n",
    "    # smooth the sensitivity function using polynomial regression\n",
    "    non_zero_indices = np.nonzero(sensitivity_function)[0]\n",
    "    non_zero_wavs = all_observed_wavs[non_zero_indices]\n",
    "    non_zero_sens = sensitivity_function[non_zero_indices]\n",
    "    x_data = non_zero_wavs\n",
    "    y_data= non_zero_sens\n",
    "\n",
    "    obs_sci_wavs = WCS2World(sci_spec)\n",
    "    sci_header = sci_spec[0].header\n",
    "    \n",
    "    # regression using astroml to get initial guesses\n",
    "    smooth_sensitivity_func = PolynomialRegression(degree = Order)\n",
    "    smooth_sensitivity_func.fit(x_data[:,None], y_data)\n",
    "    smooth_sensitivity_y_sci =  smooth_sensitivity_func.predict(obs_sci_wavs[:,None])  \n",
    "\n",
    "\n",
    "    model_coeffs =smooth_sensitivity_func.coef_\n",
    "    a_model, b_model, c_model = model_coeffs\n",
    "    print(a_model, b_model, c_model)\n",
    "\n",
    "\n",
    "    \n",
    "    # initial guess for coefficients (a, b, c) from AstroML to be used by scipy\n",
    "    initial_guess = [a_model,b_model,c_model]\n",
    "\n",
    "    if max_throughput_wav !=None:\n",
    "        x_c = max_throughput_wav\n",
    "        constraints = [\n",
    "        {'type': 'eq', 'fun': lambda coeffs: derivative_constraint(coeffs, x_c)},    # activate this when dealing with blue data\n",
    "    ]\n",
    "\n",
    "    else:\n",
    "        constraints = []\n",
    "    \n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_guess,\n",
    "        args=(x_data, y_data),\n",
    "        constraints=constraints,\n",
    "\n",
    "        method = 'SLSQP',\n",
    "        options={'maxiter': 100000}\n",
    "\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        fitted_coeffs_scaled = result.x\n",
    "        a = fitted_coeffs_scaled[0]\n",
    "        b = fitted_coeffs_scaled[1]\n",
    "        c = fitted_coeffs_scaled[2]\n",
    "        fitted_coeffs = a,b,c\n",
    "        print(\"Fitted coefficients:\", fitted_coeffs)\n",
    "    else:\n",
    "        print(\"No solution found\")\n",
    "     \n",
    "    \n",
    "    x_full = np.linspace(x_data[0]-1000,x_data[-1]+1000, x_data.shape[0])\n",
    "    y_smooth_sci = custom_poly(obs_sci_wavs, fitted_coeffs)\n",
    "    y_smooth = custom_poly(x_data, fitted_coeffs)\n",
    "    y_smooth_full = custom_poly(x_full, fitted_coeffs)\n",
    "    \n",
    "    smooth_sensitivity_y_astroml = smooth_sensitivity_func.predict(x_full[:,None])\n",
    "\n",
    "\n",
    "\n",
    "    # plot the sensititvy function \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.xlabel('Wavelength (Å)')\n",
    "    plt.ylabel('Count/Flux (#/erg/cm$^2$/s/Å)')\n",
    "    plt.title('Smooth Function')\n",
    "    plt.plot(x_data, y_data, label = 'Combined Sensitivity Function', color = 'blue')\n",
    "    plt.plot(x_full, y_smooth_full, label = 'Smooth Function', color = 'r')\n",
    "    plt.plot(x_data, y_smooth,linestyle = 'dashed', color = 'r')\n",
    "    \n",
    "    # plot the smooth sensitivity function, along with the polynomial for reference\n",
    "    plt.plot(x_full, smooth_sensitivity_y_astroml, color = 'black', label = 'Initial Guess', linestyle='dashed')\n",
    "    plt.plot([],[], label = 'Order: '+ str( Order), color = 'w')\n",
    "    plt.legend()\n",
    "        \n",
    "\n",
    "    plot_smooth_sens_filename = f'combined_smooth_sens_function.png'\n",
    "    plot_smooth_sens_full_path = os.path.join(star_diagnostics, plot_smooth_sens_filename)\n",
    "    plt.savefig(plot_smooth_sens_full_path, facecolor='w', transparent=False, overwrite=True)\n",
    "    check_skysub(cont=19, sky =5, data = sci_data)\n",
    "\n",
    "    # put it all together and save, works for either 1D or 2D science spectra\n",
    "    if sci_data.data.ndim == 1:\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.plot(sci_data['LAMBDA'], sci_data['SPEC'])\n",
    "        plt.xlabel('Wavelength (Å)')\n",
    "        plt.ylabel('Flux (Counts)')\n",
    "        plt.title('Uncalibrated Science Spectrum')\n",
    "        plt.ylim(-10, 300)\n",
    "    \n",
    "        new_flux = (sci_data['SPEC'])/sci_interval_sens_func        \n",
    "        plt.plot(sci_data['LAMBDA'], new_flux)\n",
    "        plt.xlabel('Wavelength (Angstroms)')\n",
    "        plt.ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "        plt.title('Calibrated Science Spectrum')\n",
    "    elif sci_data.data.ndim == 2:\n",
    "        newFITS= fits.HDUList()\n",
    "        header = sci_spec[0].header\n",
    "        header.append(('FLUXUNIT', '1E-17 erg/cm^2/s/Ang'))\n",
    "        hdu=fits.PrimaryHDU(None, header)\n",
    "        new_flux = []\n",
    "        for m in range(len(sci_data[0,:])):\n",
    "            new_flux.append(sci_data[:,m]/y_smooth_sci[m]) \n",
    "        data = (new_flux)\n",
    "        data_trans = np.transpose(data)\n",
    "        hdu.data = data_trans\n",
    "        print(hdu.shape)\n",
    "        cal_plot_data = np.sum(hdu.data, axis = 0)\n",
    "        newFITS.append(hdu)\n",
    "        newFITS.writeto(os.path.abspath(os.path.join(SDSS_star_path, \"..\"))+\"/FLUXcal_\"+(file_name), overwrite=True)\n",
    "        obs_sci_wavs = obs_sci_wavs*wave_units\n",
    "        uncal_plot_data = np.sum(sci_data, axis = 0)\n",
    "        path1D = os.path.abspath(os.path.join(SDSS_star_path, \"..\"))+\"/FLUXcal_\"+('1' + file_name[1:])\n",
    "        cal_plot_data, newFITS1D = extract1D(newFITS, path1D, Order = 6)\n",
    "\n",
    "\n",
    "        # plots the calibrated and uncalibrated star spectrum from SALT.\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True,figsize=(20,20))\n",
    "        ax1.set_title('Observed Science Spectrum')\n",
    "        ax1.plot(obs_sci_wavs, uncal_plot_data, color = 'darkorange')  \n",
    "        ax1.set_ylabel('Counts')\n",
    "        ax2.set_title('Flux Calibrated Science Spectrum')\n",
    "        ax2.plot(obs_sci_wavs, cal_plot_data, color='blue') \n",
    "        ax2.set_xlabel('Wavelength (Å)') \n",
    "        ax2.set_ylabel('Flux (erg/cm$^2$/s/Å)')  \n",
    "        \n",
    "\n",
    "    return cal_plot_data, uncal_plot_data, obs_sci_wavs, hdu, newFITS, sci_data, star_diagnostics, y_smooth_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add818de-c26c-4230-899e-42b570b6cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skysub(cont, sky, data):\n",
    "    '''\n",
    "    Used only for star spectra. where there is poor sky subtraction at the top and bottom rows. Measures the median values of the top and bottom\n",
    "    two rows and re-subtracts the negative sky values. Returns corrected data.\n",
    "    '''\n",
    "    plt.figure(figsize=(30,10))\n",
    "    image_data = np.nan_to_num(data)\n",
    "    plt.imshow(image_data,cmap='gray',aspect='auto', vmin = np.percentile(image_data, 5), vmax = np.percentile(image_data, 95))\n",
    "    plt.gca().invert_yaxis()\n",
    "    sky_rows_l = data[:2]\n",
    "    sky_rows_u = data[-2:]\n",
    "    sky_vals_l = np.nanmedian(sky_rows_l, axis =0)\n",
    "    sky_vals_u = np.nanmedian(sky_rows_u, axis =0)\n",
    "    sky_vals = np.minimum(sky_vals_l,sky_vals_u)\n",
    "    return data-sky_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b4457-3091-4b38-9401-8a681e2b5cbe",
   "metadata": {},
   "source": [
    "## - RSSMOS Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d2ac2-b860-458f-aa48-c2711e094ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run RSSMOSPipelines trace fitting and extraction routine, then save 1d extractions\n",
    "def extract1D(hdu,path, Order=4):\n",
    "    '''\n",
    "    Extraction routine that utilises RSSMOSPipeline's profile fitter which returns trace centers and sigmas at each pixel of a given 2D spectrum (hdu). The centers are then\n",
    "    subject to polynomial fitting with a given Order, and a profile is made. The product of the profile and 2D data are then summed to give the\n",
    "    extracted 1D spectrum, which is then saved as a fits file in 'path'. Returns the 1D extracted spectrum and its fits file. \n",
    "    '''    \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Now extracting 1D')\n",
    "    # multiple by scalar since values are extremely small and can throw off profile fitter. \n",
    "    scalar = 1e20\n",
    "    data_norm  = np.ma.masked_array(hdu[0].data*scalar, mask=np.isnan(hdu[0].data*scalar))\n",
    "\n",
    "    # utilise RSSMOSPipeline profile fitting routine.\n",
    "    importlib.reload(rss)\n",
    "    rss_extract = rss.finalExtraction(data_norm)\n",
    "    centers = rss_extract[3]\n",
    "    sigmas = 2*rss_extract[4]\n",
    "    \n",
    "    # create dispersion and spatial arrays to be used for fitting. RSSMOSPipeline returns -99, -99 for masked data, to be easily masked out.\n",
    "    disp=np.arange(data_norm.shape[1])\n",
    "    spatial = np.arange(data_norm.shape[0])\n",
    "    mask=np.greater(centers, 0)\n",
    "\n",
    "\n",
    "    # fitting trace with order\n",
    "    coeffs = np.polyfit(disp[mask], centers[mask], Order) \n",
    "    trace_center = np.polyval(coeffs, disp[mask])\n",
    "    trace_sigma =np.median(sigmas[mask])\n",
    "\n",
    "    # make weighted profile and sum product of profile and 2D data. Divide out original scalar to obtain 1D extracted spectra. \n",
    "    weighted_prof = np.zeros_like(data_norm)\n",
    "    for i in disp:\n",
    "        weighted_prof[:,i] = np.exp(-((spatial-trace_center[i])**2)/(2*sigmas[i]**2))\n",
    "\n",
    "    signal_norm=np.nansum(data_norm*weighted_prof, axis = 0)\n",
    "    signal = signal_norm/scalar\n",
    "\n",
    "\n",
    "    \n",
    "    # save extraction to 'path'\n",
    "\n",
    "    # for combined spectra with saved wavelengths in second hdu. \n",
    "    if len(hdu) ==2:\n",
    "        header_data = hdu[0].header.copy()\n",
    "        header_wcs = hdu[1].header.copy()\n",
    "        data_wcs = hdu[1].data\n",
    "        \n",
    "        fits_hdu = fits.PrimaryHDU(signal.filled(fill_value=np.nan), header_data)\n",
    "        fits_wcs = fits.ImageHDU(data_wcs, header_wcs)\n",
    "        fits1D = fits.HDUList([fits_hdu, fits_wcs])\n",
    "        fits1D.writeto(path, overwrite=True)\n",
    "\n",
    "\n",
    "    # for inidividual spectra that can be run with WCS2World.\n",
    "    else:\n",
    "        header = hdu[0].header.copy()\n",
    "        fits1D = fits.HDUList()\n",
    "        fits_hdu =fits.PrimaryHDU(signal.filled(fill_value=np.nan), header) \n",
    "        fits1D.append(fits_hdu)\n",
    "        fits1D.writeto(path, overwrite=True)\n",
    "\n",
    "    return signal, fits1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d540f-4b9f-46fc-9a6e-af5a9eff035a",
   "metadata": {},
   "source": [
    "## - Continuum Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76991dea-8269-428d-a74d-4897d3549701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_continuum(dispersion_axis, signal, order, window, spectral_region):\n",
    "    '''\n",
    "    Measurees the continuum level of a spectrum using Specutils, then returns a Spectrum1D object for both the original spectrum and\n",
    "    a continuum-subtracted spectrum. This is because Specutils line flux routines require continuum subtracted spectra. Meanwhile, a \n",
    "    polynomial is fitted to the spectrum, and the standard deviation of the root mean squared at each pixel is used for measuring uncertainties in \n",
    "    the line flux measurements. \n",
    "    '''    \n",
    "\n",
    "    # first convert nans to zeros\n",
    "    signal = np.nan_to_num(signal)\n",
    "\n",
    "    # fit a model and meassure residuals\n",
    "    model =models.Polynomial1D(degree=order)\n",
    "    fit = LevMarLSQFitter()\n",
    "    model_fit = fit(model, dispersion_axis,signal)\n",
    "    new_y = model_fit(dispersion_axis)\n",
    "    residuals = signal-new_y\n",
    "    \n",
    "    # measure uncertainty using rms at each pixel\n",
    "    mean_squared = median_filter(residuals**2, size=window, mode='nearest')\n",
    "    rms = np.sqrt(mean_squared)*flux_units\n",
    "    uncertainty = StdDevUncertainty(rms)\n",
    "\n",
    "    # make a Spectrum1D object with spectrum, then measure its continuum\n",
    "    spec1D_with_continuum = Spectrum1D(spectral_axis = dispersion_axis, flux = signal*flux_units,uncertainty=uncertainty)\n",
    "    continuum_fit = fit_continuum(spec1D_with_continuum, window = spectral_region)\n",
    "    continuum = continuum_fit(dispersion_axis)\n",
    "\n",
    "    # subtract continuum then make another Spectrum1D object for continuum subtracted spectrum\n",
    "    signal_no_continuum = signal-continuum.value\n",
    "    spec1D_no_continuum = Spectrum1D(spectral_axis = dispersion_axis, flux = signal_no_continuum*flux_units,uncertainty=uncertainty)\n",
    "    \n",
    "    return spec1D_with_continuum, spec1D_no_continuum, continuum,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c806267-6d1d-4402-83a3-7dc7956983a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_src(RA,Dec,HETDEX_path,version = 'v3.2'):\n",
    "    '''\n",
    "    Currently only usable if youre literature spectra are from HETDEX. Reads in the hetdex_sc1_{version}.escv \n",
    "    and the hetdex_sc1_spec_{}.fits files. Follows a similar structure to how HETDEX\n",
    "    suggests finding information on spectra. With inputted RA and Dec values derived from HETDEX, finds the object\n",
    "    and returns its spectrum, wavelength array, and other useful information to be used for continuum comparison.\n",
    "    '''    \n",
    "\n",
    "    # open source table and spec files to access spectra, wavelengths\n",
    "    source_table = Table.read(os.path.join( HETDEX_path, 'hetdex_sc1_{}.ecsv'.format(version)))  \n",
    "    hetdex_hdu = fits.open( os.path.join( HETDEX_path, 'hetdex_sc1_spec_{}.fits'.format(version)))\n",
    "    spec = hetdex_hdu['SPEC'].data\n",
    "    spec_err = hetdex_hdu['SPEC_ERR'].data\n",
    "    wave_rect = hetdex_hdu['WAVELENGTH'].data*wave_units\n",
    "\n",
    "    # uses coordinates to find target information\n",
    "    source_coords = SkyCoord(ra = source_table['RA'], dec= source_table['DEC'])\n",
    "    coord = SkyCoord(ra=RA*u.deg, dec=Dec*u.deg)\n",
    "    sel_match = source_coords.separation(coord) < 1.*u.arcsec\n",
    "    source_id = source_table['source_id'][sel_match][0]\n",
    "    name = source_table['source_name'][sel_match][0]\n",
    "    return source_table, hetdex_hdu, spec, spec_err, wave_rect, source_coords, coord, sel_match, source_id, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864edc8-76af-4507-9187-5bff62f95009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuum_comparison(SLIT,RA,Dec, HETDEX_path,mult_bias):\n",
    "    '''\n",
    "    Uses specutils to measure continua over a common wavelength range and compares the measurements between literature spectra (HETDEX in this case) \n",
    "    and observed spectra from SALT. Using the same inputted path, RA, and Dec used for read_src, it finds the targets and performs measurements. \n",
    "    Given a multiplicative bias derived from literature comparison, it will correct for that, then plot the litertaure and observed spectra together\n",
    "    allowing the user to see how close they are. Also plots the measured continua for comparison.\n",
    "    '''   \n",
    "\n",
    "    # finds the paths, specs, and other important information from flux_calibrated_specs and read_src\n",
    "    full_settings,full_settings1D,HETDEX_range_settings, combined_spec1D, color, path_dict = flux_calibrated_specs(SLIT)\n",
    "    source_table, hetdex_hdu, spec, spec_err, wave_rect, source_coords, coord, sel_match, source_id, name = read_src(RA,Dec,path_dict[\"HETDEX_path\"],version = 'v3.2')\n",
    "    HETDEX_data = spec[sel_match][0]*1e-17\n",
    "\n",
    "    # get plots ready\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True,figsize=(20,30))\n",
    "    plt.ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "    plt.xlabel('Wavelength (Å)')\n",
    "    ax2.set_xlabel('Wavelength (Å)')\n",
    "    ax2.set_ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "    ax3.set_xlabel('Wavelength (Å)')\n",
    "    ax3.set_ylabel('Flux (erg/cm$^2$/s/Å)')\n",
    "    ax1.set_title('Observed Continua vs. HETDEX Continuum')\n",
    "    ax2.set_title('Constituent Spectra vs. HETDEX Spectrum')\n",
    "    ax3.set_title('Combined Spectrum vs. HETDEX Spectrum')\n",
    "    ax2.plot(wave_rect, HETDEX_data, label ='HETDEX Spectrum')\n",
    "    ax3.plot(wave_rect, HETDEX_data, label ='HETDEX Spectrum')\n",
    "\n",
    "    # find min and max wavelengths for all settings that are wihtin HETDEX range (blue and green settings only)\n",
    "    min_wav = min(WCS2World(hdu)[0] for hdu in HETDEX_range_settings)\n",
    "    max_wav = max(WCS2World(hdu)[-1] for hdu in HETDEX_range_settings)\n",
    "\n",
    "\n",
    "    # make a Spectrum1D object and fit continua for literature spectra\n",
    "    HETDEX_Spec = Spectrum1D(spectral_axis = wave_rect, flux = HETDEX_data*flux_units)\n",
    "    HETDEX_continuum_fit = fit_continuum(HETDEX_Spec)\n",
    "    HETDEX_continuum = HETDEX_continuum_fit(wave_rect)\n",
    "    ax1.plot(wave_rect, HETDEX_continuum, label = 'HETDEX Continuum')\n",
    "\n",
    "\n",
    "\n",
    "    # run through each individual spectra that lies in the literatue spectrum range (in this case, blue and green settings only) and \n",
    "    # make Spectrum1D objects for each, measure continua, and plot. \n",
    "    sci_continua = []\n",
    "    print('Green --> Blue')\n",
    "    for hdu in HETDEX_range_settings:\n",
    "        sci_data = hdu[0].data*mult_bias\n",
    "        waves=WCS2World(hdu)*wave_units\n",
    "        # we use the minimum and maximum values of the overlap wavelengths and make a spectral region from them.\n",
    "        spectral_region = SpectralRegion(max(wave_rect[0], waves[0]), min(wave_rect[-1], waves[-1]))\n",
    "        sci_signal_spec1d, sci_signal_nocont_spec1d, sci_continuum, sci_new_y = measure_continuum(waves, sci_data, order=6,window=100, spectral_region = spectral_region)\n",
    "        ax1.plot(waves, sci_continuum, label = 'Observed Continuum')\n",
    "        ax2.plot(waves, sci_data, alpha = 0.3, label = 'Individual Spectrum')\n",
    "\n",
    "        HETDEX_continuum_fit_range = fit_continuum(HETDEX_Spec, window = spectral_region)\n",
    "        spec_range = np.arange(spectral_region.lower.value, spectral_region.upper.value)*wave_units\n",
    "        HETDEX_continuum_range = HETDEX_continuum_fit_range(spec_range)\n",
    "        #ax1.plot(spec_range, HETDEX_continuum_range, label = 'HETDEX Continuum')\n",
    "        print(f'HETDEX = {np.round(np.median(HETDEX_continuum_range)/1e-16,8)}',f'Observed = {np.round(np.median(sci_continuum)/1e-16,8)}')\n",
    "        sci_continua.append(sci_continuum)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # does the same thing as the for loop above, but for the reprojected spectrum     \n",
    "    sci_data_comb = combined_spec1D[0].data*mult_bias\n",
    "    waves_comb = combined_spec1D[1].data*wave_units\n",
    "    spectral_region_comb = SpectralRegion(max(wave_rect[0], waves_comb[0]),min(wave_rect[-1], waves_comb[-1]))\n",
    "    sci_signal_spec1d_comb, sci_signal_nocont_spec1d_comb, sci_continuum_comb, sci_new_y_comb =measure_continuum(waves_comb, sci_data_comb, order=6,window=100, spectral_region=spectral_region_comb)\n",
    "    HETDEX_continuum_fit_range_comb = fit_continuum(HETDEX_Spec, window = spectral_region_comb)\n",
    "    HETDEX_continuum_range_comb = HETDEX_continuum_fit_range_comb(wave_rect)\n",
    "    print(f'HETDEX Combined = {np.round(np.median(HETDEX_continuum_range_comb)/1e-16,8)}',f'Observed Combined = {np.round(np.median(sci_continuum_comb)/1e-16,8)}')\n",
    "    ax1.plot(waves_comb, sci_continuum_comb, label = 'Observed Reprojected Continuum')\n",
    "    ax3.plot(waves_comb, sci_data_comb, label = 'Observed Reprojected Spectrum',alpha = 0.5, color = 'purple')\n",
    "    ax1.set_ylim(ax2.get_ylim())\n",
    "    ax3.set_ylim(ax2.get_ylim())\n",
    "    plt.xlim(wave_rect[0].value-200, wave_rect[-1].value+200)\n",
    "    ax1.legend(loc = 'upper left')\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    ax3.legend(loc = 'upper left')\n",
    "    #plt.xlim(4600,5250)\n",
    "    plt.ylim(-1e-16,4e-16)\n",
    "    plt.savefig(path_dict[\"dir_mask\"]+\"/\"+f'continuum_comparison_SLIT{SLIT}', facecolor='w', transparent=False, overwrite=True)\n",
    "\n",
    "    return HETDEX_continuum, sci_continuum_comb, sci_continua\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7d202-b9d3-44dc-9765-bedf7b3d6134",
   "metadata": {},
   "source": [
    "## - Full-Optical Spectroscopic Combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391a7d0-a2c1-40d1-8266-79264c258066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolver(k, SLIT):\n",
    "    '''\n",
    "    Given a target (slit) and a resolution decreasing parameter k, reprojects all observed settings onto an exponential wavelength array with decreasing resolution at higher wavelengths. \n",
    "    It first makes the exponential wavelength array using the minimum and maximum value for the entire wavelength range. For each setting, \n",
    "    it will interpolate the data onto this new exponential array, with NaNs as a fill value. Once all are reprojected, they are averaged together.\n",
    "    '''   \n",
    "\n",
    "\n",
    "    # finds the paths, specs, and other important information from flux_calibrated_specs and read_src\n",
    "    full_settings,full_settings1D,HETDEX_range_settings, combined_spec, color_list, paths_dict = flux_calibrated_specs(SLIT)\n",
    "    paths = get_paths(data_dir, config_name)\n",
    "\n",
    "    # here we find total pixels for our slit size, which is used to find central resolution values. these can be changed to cater to other programs.\n",
    "    slit_width = 2*u.arcsec\n",
    "    arcsec_per_pix = 0.1267*u.arcsec*(u.pix**-1)\n",
    "    tot_pix = (slit_width/arcsec_per_pix)/2\n",
    "    # find the minimum and maximum wavelengths   \n",
    "    min_wav = min((WCS2World(hdu)[0]) for hdu in full_settings)\n",
    "    max_wav = max((WCS2World(hdu)[-1]) for hdu in full_settings)\n",
    "\n",
    "    \n",
    "    print(max_wav)\n",
    "    print(min_wav)\n",
    "    lambda_start = min_wav\n",
    "    lambda_end = max_wav\n",
    "    \n",
    "    \n",
    "    A=lambda_start/(1+np.exp(1/k))\n",
    "    numbins = int(k*np.log((lambda_end/A)-1))\n",
    "    L=np.linspace(1, numbins, numbins)\n",
    "    \n",
    "    # calculate true wavelengths and find resolution per pixel values\n",
    "    true_wavs = np.empty_like(L-1)\n",
    "    resolution_pix = np.empty_like(L)\n",
    "    true_wavs = A*(np.exp(L/k)+1)\n",
    "    for i in range(len(L)):\n",
    "        if i ==0:\n",
    "            resolution_pix[i] = np.nan\n",
    "        else:\n",
    "            resolution_pix[i] = true_wavs[i]/np.diff(true_wavs)[i-1]\n",
    "\n",
    "    \n",
    "    # get the wavelength arrays for all settings\n",
    "    resolution_settings = []\n",
    "    wavelength_arrays = []\n",
    "    center_vals = []\n",
    "    for hdu in full_settings:\n",
    "        wavelength_array=WCS2World(hdu)\n",
    "        wavelength_arrays.append(wavelength_array)\n",
    "        cent_val = np.median(wavelength_array)\n",
    "        print(cent_val)\n",
    "        center_vals.append(cent_val)\n",
    "        wav_slope = hdu[0].header['CDELT1']*wave_units\n",
    "        per_res_element = wav_slope*tot_pix\n",
    "        R_cent = cent_val*wave_units/per_res_element\n",
    "        print(R_cent)\n",
    "\n",
    "    # get the resolutions for each setting.\n",
    "    for wav, hdu in zip(wavelength_arrays, full_settings):\n",
    "        res_setting = wav/hdu[0].header['CDELT1']\n",
    "        resolution_settings.append(res_setting)\n",
    "    \n",
    "        \n",
    "    # make inteprolation functions\n",
    "    interpolation_functions = []\n",
    "    for hdu, wavelength_array in zip(full_settings, wavelength_arrays):\n",
    "        dat = hdu[0].data\n",
    "        dat[dat==0]=np.nan\n",
    "        interp_func = interp1d(wavelength_array,dat,bounds_error=False, fill_value=np.nan)\n",
    "        interpolation_functions.append(interp_func)\n",
    "    \n",
    "\n",
    "    # generate new data projected onto an exponential wavelength array\n",
    "    data_list = []\n",
    "    for funcs in interpolation_functions:\n",
    "        comb_data = funcs(true_wavs)\n",
    "        data_list.append(comb_data)\n",
    "\n",
    "    # just in case some data is not the same size, we can chop off data. If you want to avoid this then you must use -F key in RSSMOSPipeline\n",
    "    # and make sure slit size remains consistent.\n",
    "    \n",
    "    # max_y_dim = max(arr.shape[0] for arr in data_list)\n",
    "    # Pad each image in projected_data to match the maximum y-dimension size\n",
    "    # padded_data = []\n",
    "    # for arr in data_list:\n",
    "    #     if arr.shape[0] < max_y_dim:\n",
    "    #         padding_size = max_y_dim - arr.shape[0]\n",
    "    #         padded_arr = np.pad(arr, ((0, padding_size),(0,0)), mode='constant', constant_values=np.nan)\n",
    "    #         padded_data.append(padded_arr)\n",
    "    #     else:\n",
    "    #         padded_data.append(arr)\n",
    "    # stack_data_list = data_list\n",
    "    \n",
    "    print(data_list[0].shape,data_list[1].shape,data_list[2].shape)\n",
    "    stack_data_list = np.stack(data_list, axis = 2)\n",
    "\n",
    "\n",
    "    # put it all together and save\n",
    "    final_stack_data = np.zeros((stack_data_list.shape[0],stack_data_list.shape[1]))\n",
    "    stack_data_list_transposed = np.moveaxis(stack_data_list, -1, 0)\n",
    "    print(stack_data_list_transposed.shape)\n",
    "\n",
    "    # some code to favor higher resolution data based on favoring_threshold, can be set to desired range but we set so green is favored over red\n",
    "    # could go with multiple of resolution instead of threshold\n",
    "    favoring_threshold=10500\n",
    "    final_stack_data = np.full(stack_data_list_transposed.shape[1:], np.nan)\n",
    "    for z in range(stack_data_list_transposed.shape[0]):\n",
    "        for i in range(stack_data_list_transposed.shape[2]):\n",
    "            data_slice = stack_data_list_transposed[z,:,i]\n",
    "            res_slice = resolution_settings[z]\n",
    "\n",
    "            # make masks where resolution is higher or lower than favoring_threshold. If data exists above and below favoring threshold,\n",
    "            # just use higher resolution data. otherwise average normally\n",
    "            high_res_mask =max(res_slice)>favoring_threshold\n",
    "            low_res_mask=max(res_slice)<favoring_threshold\n",
    "            if high_res_mask.any():\n",
    "                high_res_avg = np.nanmean(data_slice[high_res_mask, :], axis=0)\n",
    "                valid_high_res_avg = ~np.isnan(high_res_avg)\n",
    "                final_stack_data[valid_high_res_avg, i] = high_res_avg[valid_high_res_avg]\n",
    "            if not high_res_mask.any() and low_res_mask.any():\n",
    "                low_res_avg = np.nanmean(data_slice[low_res_mask, :], axis=0)\n",
    "                valid_low_res_avg = ~np.isnan(low_res_avg)\n",
    "                final_stack_data[valid_low_res_avg, i] = low_res_avg[valid_low_res_avg]\n",
    "                \n",
    "    combined_data = final_stack_data\n",
    "\n",
    "\n",
    "    # plot the wavelength vs L array.\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(L, true_wavs)\n",
    "    plt.xlabel('L')\n",
    "    plt.ylabel('Wavelength')\n",
    "    plt.title('Wavelength vs. L')\n",
    "    \n",
    "    # plot the resolution vs wavelength for each of the six settings and for the projected wavelength\n",
    "    plt.figure(figsize=(20,10))\n",
    "    colors_used = []\n",
    "    for arr, res, color in zip(wavelength_arrays[::-1], resolution_settings[::-1], color_list[::-1]):\n",
    "        if color in colors_used:\n",
    "            plt.plot(arr, res, color = color)\n",
    "        else:\n",
    "            plt.plot(arr, res, color = color, label = f'{color} settings')\n",
    "        colors_used.append(color)\n",
    "        plt.ylabel('Resolution Per Pixel')\n",
    "        plt.xlabel('Wavelength')\n",
    "        plt.title('Resolution Per Pixel vs. Wavelength')\n",
    "    plt.plot(true_wavs, resolution_pix, label = 'Reprojected', color = 'purple')\n",
    "    plt.axhline(favoring_threshold, color = 'black', linestyle = 'dashed', label = 'Threshold')\n",
    "    plt.legend()\n",
    "    plt.savefig(paths[\"dir_mask\"]+f\"/resolution_per_pixel_{SLIT}.png\", facecolor='w', transparent=False, overwrite=True)\n",
    "    \n",
    "\n",
    "    print(f'Max Resolution = {np.max(resolution_pix[1:])}')\n",
    "    print(f'Min Resolution = {np.min(resolution_pix[1:])}')\n",
    "    print(f'Numbins = {numbins}')\n",
    "    print(f'A = {A}')\n",
    "    print(f'True Wavelengths: {true_wavs}')\n",
    "\n",
    "\n",
    "    # save hdu and associated non-linear wavelength array\n",
    "    for hdu in full_settings:\n",
    "        new_image_header = hdu[0].header.copy()\n",
    "    new_image_header['CRVAL1'] = L[0]\n",
    "    new_image_header['CRPIX1'] = 1\n",
    "    new_image_header['CDELT1'] = np.diff(L)[0]\n",
    "    new_image_header['CD1_1'] = np.diff(L)[0]\n",
    "    new_image_header['CUNIT1'] = 'Custom'\n",
    "    new_image_header['A'] = A\n",
    "    new_image_header['k'] = k\n",
    "    new_image_header['COMMENT1'] = 'To get non-linear wavelengths, perform following: A*(exp(WCS/k)+1)'\n",
    "    new_image_header['COMMENT2'] = 'Alternatively, wavelengths can be accessed in the second HDU'\n",
    "    new_image_hdu = fits.PrimaryHDU(combined_data, header=new_image_header)\n",
    "    new_wcs_hdu = fits.ImageHDU(true_wavs, name='WAVELENGTHS')\n",
    "    new_wcs_hdu.header['EXTNAME'] = 'WAVELENGTHS'\n",
    "    new_wcs_hdu.header['CUNIT'] = 'Angstrom'\n",
    "    new_wcs_hdu.header['COMMENT'] = 'Non-linear wavelength array'\n",
    "    hdulist = fits.HDUList([new_image_hdu,new_wcs_hdu])\n",
    "    path2D = paths[\"dir_mask\"]+f'/FLUXcal_2D_noSky_{paths[\"mask_name\"]}_{paths[\"mask_id\"]}_{SLIT}_comb.fits'\n",
    "    hdulist.writeto(path2D, overwrite = True)\n",
    "    path1D = paths[\"dir_mask\"]+f'/FLUXcal_1D_noSky_{paths[\"mask_name\"]}_{paths[\"mask_id\"]}_{SLIT}_comb.fits'\n",
    "    extract1D(hdulist, path1D)\n",
    "\n",
    "    return L, true_wavs, A, numbins, full_settings, combined_data,hdulist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17926025-6eec-4a87-bd6a-cb956cfb01c5",
   "metadata": {},
   "source": [
    "## - Line Inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775f87b-e424-4fc1-a3f8-70714bd89a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_inspector(hdu_dir,SLIT, emline, line_range, obj_name, mult_bias):\n",
    "    '''\n",
    "    Given the directory of a target, slit number, emission line wavelength range and type, will plot the 1D spectrum and measure the \n",
    "    integrated line flux using Specutils line_flux. \n",
    "    '''   \n",
    "\n",
    "    # open 1D fits file\n",
    "    hdu = fits.open(glob.glob(f'{hdu_dir}FLUXcal_1D*SLIT{SLIT}*.fits')[0])\n",
    "    signal = hdu[0].data*mult_bias\n",
    "    if len(hdu) ==2:\n",
    "        wavelengths = hdu[1].data\n",
    "\n",
    "    else:\n",
    "        wavelengths = WCS2World(hdu)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.ylabel('Flux (erg/cm$^2$/s/Å)') \n",
    "    plt.title(obj_name)\n",
    "\n",
    "    # open dictionary of emission line rest wavelengths \n",
    "    path_to_rest_wavs = data_dir+'rest_wavelengths.txt'\n",
    "    emline_dict = {}\n",
    "    with open(path_to_rest_wavs) as emline_file:\n",
    "        next(emline_file)\n",
    "        for line in emline_file:\n",
    "           (emline_type, rest_wav) = line.split()\n",
    "           emline_dict[str(emline_type)] = float(rest_wav)\n",
    "    em = emline_dict[emline]\n",
    "    print(em)\n",
    "\n",
    "    \n",
    "    line_start,line_end = [float(x) for x in line_range.split('-')]\n",
    "    continuum_region = SpectralRegion(wavelengths[0]*wave_units, wavelengths[-1]*wave_units)\n",
    "    \n",
    "    # find em line region and indices, make Spectrum1D objects both before and after continuum subtraction of spectra.\n",
    "    spec1D,spec1D_nocont,continuum, new_y = measure_continuum(wavelengths*wave_units, signal, order = 6, window = 100, spectral_region = continuum_region)\n",
    "    emline_indices = np.where((spec1D_nocont.spectral_axis >= line_start*wave_units) & (spec1D_nocont.spectral_axis <= line_end*wave_units))[0]\n",
    "    emline_range = spec1D_nocont.spectral_axis[emline_indices]\n",
    "    emline_fluxes = spec1D_nocont.flux[emline_indices]\n",
    "    emline_cent = spec1D_nocont.spectral_axis[emline_indices[np.argmax(emline_fluxes)]]\n",
    "    \n",
    "    spectral_region = SpectralRegion(line_start*wave_units, line_end*wave_units)\n",
    "    \n",
    "    \n",
    "    center = centroid(spec1D_nocont, spectral_region)\n",
    "    \n",
    "    \n",
    "    # get line flux of emission line\n",
    "    line_flux_cont = line_flux(spec1D, regions=spectral_region)\n",
    "    line_flux_true = line_flux(spec1D_nocont, regions=spectral_region)\n",
    "    \n",
    "    \n",
    "    plt.xlim(line_start-150,line_end+150)\n",
    "    plt.axvline(line_start, label = 'emission line range')\n",
    "    plt.axvline(line_end)\n",
    "\n",
    "    # gaussian fitting of emission line\n",
    "    g_init = Gaussian1D(amplitude=np.max(emline_fluxes), mean=emline_cent, stddev=1*wave_units, fixed={'mean': False})\n",
    "    fit_g = fit_lines(spec1D_nocont,g_init, window=(line_start*wave_units, line_end*wave_units))\n",
    "    gauss = fit_g(spec1D_nocont.spectral_axis)\n",
    "    amplitude = fit_g.amplitude.value\n",
    "    stddev = fit_g.stddev.value\n",
    "    fit_g_area = amplitude * np.sqrt(2 * np.pi) * stddev\n",
    "\n",
    "    \n",
    "    print(f'Gaussian 1+z = {np.round(fit_g.mean/(em*wave_units),5)}')\n",
    "    print(f'Centroid 1+z = {np.round(center/(em*wave_units),5)}')\n",
    "    \n",
    "    \n",
    "    print(f'Central Gaussian Wavelength = {np.round(fit_g.mean.value, 1)}')\n",
    "    print(f'Central Centroid Wavelength = {np.round(center, 1)}')\n",
    "    print(line_flux_cont/1e-16)\n",
    "    print(f'Line Flux = {np.round(line_flux_true/1e-16, 8)}, Error ={np.round(line_flux_true.uncertainty/1e-16,8)} ')\n",
    "    print(f'Gaussian Line Flux: {np.round(fit_g_area/1e-16,8)}')\n",
    "    # plt.plot([],[], label = 'Line Flux ($10^{-17} erg/cm^2/s$): '+linelegend, color = 'w')\n",
    "    plt.plot(spec1D_nocont.spectral_axis,gauss, color = 'g')\n",
    "    #plt.plot(spec1D_nocont.spectral_axis,continuum, color = 'r')\n",
    "    #plt.plot(spec1D_nocont.spectral_axis,new_y, color = 'yellow')\n",
    "    plt.plot(spec1D_nocont.spectral_axis,spec1D_nocont.flux, color = 'b', alpha =0.8)\n",
    "    plt.ylim(-0.5e-16, 2.25e-16)\n",
    "    plt.axhline(0, color = 'black')\n",
    "    plt.legend()\n",
    "    #plt.savefig(dir_mask+\"/1doii.png\", facecolor='w', transparent=False, overwrite=True)\n",
    "    return emline_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f1fd9-103e-4d65-81ba-6c56e3c6529a",
   "metadata": {},
   "source": [
    "# Run Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fdbe9-e0b5-4c25-8525-a94abae6ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare paths for running pipeline below. Multiplicative bias correction value needed, otherwise set as 1 for no correction.\n",
    "path_dict=get_paths(data_dir, config_name)\n",
    "mult_bias = 10**0.286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00102921-83be-4c7a-8046-efa23b8155b5",
   "metadata": {},
   "source": [
    "## - Flux Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a8b6c-d8e6-47e5-899a-7e1fb94ed42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare dither, grating (color), slit, max throughput wavelength, and desired paths for SDSS star spectra and science spectra.\n",
    "dith = \"-\"\n",
    "color = path_dict[\"dir_green\"]\n",
    "SLIT =12\n",
    "\n",
    "max_throughput_wav =5000\n",
    "if dith == \"+\":\n",
    "    path = path_dict[\"u_path\"]\n",
    "\n",
    "elif dith == \"-\":\n",
    "    path = path_dict[\"l_path\"]\n",
    "SDSS_star_path = f'{color}/Dither{dith}/SDSS_Stars/'\n",
    "sci_spec_path =f'{color}{path}2D_noSky_{path_dict[\"mask_name\"]}_{path_dict[\"mask_id\"]}_SLIT{str(SLIT)}.fits'\n",
    "starSLITS = [2,8]\n",
    "Order=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b740e5-005e-4d08-845e-65dfb741b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run flux calibration\n",
    "cal_plot_data, uncal_plot_data, obs_sci_wavs, hdu, newFITS, sci_data,star_diagnostics, sensitivity_function = flux_calibration(sci_spec_path, SDSS_star_path,Order, starSLITS, max_throughput_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f16b06-6a2f-46c6-9fc3-0894557c1d56",
   "metadata": {},
   "source": [
    "## - Reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d68bef-51e8-40d8-b939-09ec4c92fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare slit number and run reprojection\n",
    "slit_num = 12\n",
    "L, true_wavs, A, numbins, full_settings, combined_data,hdulist = resolver(k=9000, SLIT=f'SLIT{slit_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7be8c8-18bf-46c6-87fb-3b820e51d40c",
   "metadata": {},
   "source": [
    "## - Line Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e854df-aeed-4696-822d-6cffbca4eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare path, emission line type and range of interest, object name (for titling plots), and the multiplicative bias to correct for\n",
    "# to run for line inspection. \n",
    "\n",
    "# if checking reprojection\n",
    "path = path_dict[\"dir_mask\"]+'/'\n",
    "\n",
    "# if checking individual settings\n",
    "#path = path_dict[\"dir_red\"]+'/Dither+/'\n",
    "line_range = '5023.5-5037.5'\n",
    "emline = 'SII6731'\n",
    "obj_name = 'HETDEX J100041.45+021331.8'\n",
    "emline_dict = line_inspector(path, 7, emline, line_range,obj_name,mult_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5aed31-a0ad-465d-ab31-4c93e4d9b23a",
   "metadata": {},
   "source": [
    "## - Continuum Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39995bdb-dc38-42b0-ae8e-1244b9a55187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare slit num and coordinates to measure and compare continua to literature spectra\n",
    "\n",
    "SLIT=7\n",
    "RA = 150.241455078125\n",
    "Dec =  2.2567691802978516\n",
    "\n",
    " \n",
    "HETDEX_continuum, sci_continuum_comb, sci_continua= continuum_comparison(SLIT,RA,Dec,path_dict[\"HETDEX_path\"],mult_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6b6a0-2e33-4cbd-91d6-eb6aed687f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
